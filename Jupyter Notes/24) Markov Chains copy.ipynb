{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Markov Chains** \n",
    "\n",
    "They are a model for describing systems that move from **state to state** via random transitions \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example: \n",
    "\n",
    "Imagine the scenario where we're the heads of a restaurant, and we only serve three items, one item per day: \n",
    "1) Burgers\n",
    "2) Pizzas \n",
    "3) Hotdogs \n",
    "\n",
    "The associated states are below: \n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/i3AkTO9HLXo/maxresdefault.jpg\" alt=\"Image Alt Text\" width=\"600\" height=\"315\">\n",
    "\n",
    "But what do all those numbers and lines mean?\n",
    "* They represent the probabilities of going from one state to another \n",
    "* Each state represents the menu item which is served that day \n",
    "\n",
    "Looking at our Markov Chain, we can observe the following states and their probabilities: \n",
    "* If we have a burger on a specific day, then the next day we will have:  \n",
    "    * A burger again with probability $0.2$\n",
    "    * A pizza with probability $0.6$\n",
    "    * A hotdog with probability $0.2$\n",
    "\n",
    "* If we have pizza on a specific day, then the next day we will have:  \n",
    "    * A burger with probability $0.3$\n",
    "    * A pizza again with probability $0$\n",
    "    * A hotdog with probability $0.7$\n",
    "\n",
    "* If we have a hotdog on a specific day, then the next day we will have:  \n",
    "    * A burger with probability $0.5$\n",
    "    * A pizza with probability $0$\n",
    "    * A hotdog again with probability $0.5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A More Formal Set Up** ##\n",
    "\n",
    "We define our state space $K = {1, 2, ... K}$ for finite $K$\n",
    "\n",
    "Transition matrix: $P$, which is a $K$ by $K$ real matrix satisfying: \n",
    "* $P(i,j) \\geq 0$       $\\forall i,j$ $\\in K$ (non-negative)\n",
    "    * This represents the probability of going from state $i$ to state $j$\n",
    "\n",
    "* $\\sum_{j} P(i,j) = 1$          $\\forall i$ $\\in$ $K$\n",
    "    * All the probabilities going out of a state sum to $1$\n",
    "\n",
    "Given any $X_0 \\in K$, defined a random sequence $X_0, X_1, X_2, ... $ by \n",
    "\n",
    "$$P[X_{n+1} = j | X_n = i, X_{n-1}, ... X_0] = P(i,j)$$\n",
    "\n",
    "This means that the probability depends **only on** $X_n = i$, or the probability of transitioning to the next state depends only on the current state, and not the sequence of events that preceded it\n",
    "\n",
    "More generally: $X_o$ has a probability distribution on $K$\n",
    "\n",
    "For the burger situation, here is the transition matrix: \n",
    "\n",
    "$$\n",
    "\\text{Transition Matrix} = \n",
    "\\begin{array}{c|ccc}\n",
    "& \\text{Burger} & \\text{Pizza} & \\text{Hotdog} \\\\\n",
    "\\hline\n",
    "\\text{Burger} & 0.2 & 0.6 & 0.2 \\\\\n",
    "\\text{Pizza} & 0.3 & 0 & 0.7 \\\\\n",
    "\\text{Hotdog} & 0.5 & 0 & 0.5 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matrix-vector formulation**\n",
    "\n",
    "Let $\\pi_{n}$ be a row vector describing the probability distribution over states after $n$ transitions, i.e. \n",
    "\n",
    "$\\pi_n (i) = P[X_{n} = i]$\n",
    "* So each element of the row vector represents the probability of being in the corresponding state after $n$ transitions\n",
    "\n",
    "Given a certain $\\pi_n$, what does $\\pi_{n+i}$ look like? \n",
    "\n",
    "$\\rightarrow \\pi_{n+i}(j) = \\sum_{i \\in K} \\pi_{n}(i) \\cdot P(i,j)$\n",
    "\n",
    "So: $\\pi_{n+i} = \\pi_{n}P$ \n",
    "\n",
    "Let us consider the following example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a two-state Markov chain with the following transition matrix:\n",
    "\n",
    "$$ P = \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{pmatrix} $$\n",
    "\n",
    "This matrix represents the probabilities of transitioning between the two states. For example, $ P_{1,1} = 0.8 $ represents the probability of transitioning from state 1 to state 1, and $ P_{2,1} = 0.4 $ represents the probability of transitioning from state 2 to state 1.\n",
    "\n",
    "Now, let's assume we start with an initial probability distribution $ \\pi_0 = [0.5, 0.5] $. This means that at the beginning, there's an equal probability of being in either state 1 or state 2.\n",
    "\n",
    "To find the probability distribution after 2 transitions ( $ \\pi_2 $ ), we can use the equation $ \\pi_{n+1} = \\pi_{n}P $:\n",
    "\n",
    "$$ \\pi_2 = \\pi_0 P^2 $$\n",
    "\n",
    "$$ \\pi_2 = [0.5, 0.5] \\times \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{pmatrix}^2 $$\n",
    "\n",
    "$$ \\pi_2 = [0.5, 0.5] \\times \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{pmatrix} \\times \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{pmatrix} $$\n",
    "\n",
    "$$ \\pi_2 = [0.5, 0.5] \\times \\begin{pmatrix} (0.8 \\times 0.8 + 0.2 \\times 0.4) & (0.8 \\times 0.2 + 0.2 \\times 0.6) \\\\ (0.4 \\times 0.8 + 0.6 \\times 0.4) & (0.4 \\times 0.2 + 0.6 \\times 0.6) \\end{pmatrix} $$\n",
    "\n",
    "$$ \\pi_2 = [0.5, 0.5] \\times \\begin{pmatrix} 0.72 & 0.28 \\\\ 0.56 & 0.44 \\end{pmatrix} $$\n",
    "\n",
    "$$ \\pi_2 = [0.5 \\times 0.72 + 0.5 \\times 0.56, 0.5 \\times 0.28 + 0.5 \\times 0.44] $$\n",
    "\n",
    "$$ \\pi_2 = [0.64, 0.36] $$\n",
    "\n",
    "So after 2 transitions, the probability distribution over the two states is approximately $ \\pi_2 = [0.64, 0.36] $. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Invariant Distribution**\n",
    "\n",
    "* Also known as the stationary distribution \n",
    "\n",
    "Definition: A distribution $\\pi$ over $K$ is **invariant** for $P$ if $\\pi P = \\pi$\n",
    "* In other words, $p$ does not change under the action of $P$\n",
    " \n",
    "* So the probability distribution over the states of a Markov chain that remains unchanged over time\n",
    "\n",
    "* Once a markov chain reaches its invariant distribution, the probability of finding the system in each state will stabilize, where further transitions will not alter probabilities\n",
    "\n",
    "Note that if $\\pi_0$ is invariant, then: \n",
    "\n",
    "$$ \\pi_n = \\pi_0 P^{n} = \\pi_0 \\forall n$$\n",
    "\n",
    "Definition: A distribution $\\pi$ over $K$ is **invariant** for $P$ if \n",
    "\n",
    "$$\\pi P = \\pi$$\n",
    "\n",
    "Finding an invariant distribution: The condition $\\pi P = \\pi$ corresponds to $K$ linear equations: \n",
    "\n",
    "The following are referred to as the **balance equations**\n",
    "\n",
    "$$ \\pi(j) = \\sum_{i \\in K} \\pi(i) P(i,j) $$\n",
    "\n",
    "* For each state $j$, the probability of being in state $j$ after transition $(\\pi(j))$ should equal the sum of the probabilities of being in all other states $(\\pi(i))$ multiplied by the probability of transitioning from each of those states to state $j(P(i,j))$\n",
    "\n",
    "* The primary purpose of these **balance equations** is to find the equilibrium distribution of the Markov chain\n",
    "* Can help us assess if a Markov chain will converge to a unique equilibrium distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Balance Equations Example**\n",
    "\n",
    "\n",
    "Let's consider a simpler example with a $(2 \\times 2)$ transition matrix for a Markov chain.\n",
    "\n",
    "Suppose we have the following transition matrix:\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "To find the invariant distribution $(\\pi = [\\pi_1, \\pi_2])$, we'll set up the balance equations for each state $(j)$:\n",
    "\n",
    "1. For state 1:\n",
    "   $$\n",
    "   \\pi_1 = \\pi_1 \\cdot 0.8 + \\pi_2 \\cdot 0.4\n",
    "   $$\n",
    "\n",
    "2. For state 2:\n",
    "   $$\n",
    "   \\pi_2 = \\pi_1 \\cdot 0.2 + \\pi_2 \\cdot 0.6\n",
    "   $$\n",
    "\n",
    "We have the following system of equations:\n",
    "\n",
    "1. For state 1:\n",
    "   $$\n",
    "   \\pi_1 = 0.8\\pi_1 + 0.4\\pi_2\n",
    "   $$\n",
    "\n",
    "2. For state 2:\n",
    "   $$\n",
    "   \\pi_2 = 0.2\\pi_1 + 0.6\\pi_2\n",
    "   $$\n",
    "\n",
    "To solve this system of equations, we can use various methods such as substitution, elimination, or matrix operations. Let's use substitution:\n",
    "\n",
    "From equation 1, we can express $\\pi_1$ in terms of $\\pi_2$:\n",
    "\n",
    "$$\n",
    "\\pi_1 - 0.8\\pi_1 = 0.4\\pi_2\n",
    "$$\n",
    "$$\n",
    "0.2\\pi_1 = 0.4\\pi_2\n",
    "$$\n",
    "$$\n",
    "\\pi_1 = 2\\pi_2\n",
    "$$\n",
    "\n",
    "Now, we substitute this expression for $(\\pi_1)$ into equation 2:\n",
    "\n",
    "$$\n",
    "\\pi_2 = 0.2(2\\pi_2) + 0.6\\pi_2\n",
    "$$\n",
    "$$\n",
    "\\pi_2 = 0.4\\pi_2 + 0.6\\pi_2\n",
    "$$\n",
    "$$\n",
    "\\pi_2 = 1\\pi_2\n",
    "$$\n",
    "\n",
    "So, we have found that $\\pi_2 = \\pi_2$, which holds true for any value of $(\\pi_2)$. This implies that $(\\pi_2)$ can take any value.\n",
    "\n",
    "Now, using the expression $(\\pi_1 = 2\\pi_2)$, we find that $(\\pi_1 = 2\\pi_2)$.\n",
    "\n",
    "Therefore, the invariant distribution $(\\pi = [\\pi_1, \\pi_2])$ can be any vector of the form $[2k, k]$, where k is any real number.\n",
    "\n",
    "To find the specific values of k, we use the constraint $(\\pi_1 + \\pi_2 = 1)$:\n",
    "\n",
    "$$\n",
    "2k + k = 1\n",
    "$$\n",
    "$$\n",
    "3k = 1\n",
    "$$\n",
    "$$\n",
    "k = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "Now, we can find $(\\pi_1)$:\n",
    "\n",
    "$$\n",
    "\\pi_1 = 2 \\times \\frac{1}{3} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "Therefore, the specific values of $(\\pi_1)$ and $(\\pi_2)$ are $(\\frac{2}{3})$ and $(\\frac{1}{3})$, respectively.\n",
    "\n",
    "Hence, the invariant distribution $(\\pi)$ is:\n",
    "\n",
    "$$\n",
    "\\pi = \\left[\\frac{2}{3}, \\frac{1}{3}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convergence to Invariant Distribution**\n",
    "\n",
    "Informal Theorem: Under mild conditions, a Markov chain converges to a unique invariant distribution, for any initial disribution $\\pi_0$\n",
    "\n",
    "There are two main conditions in order for a unique convergence to an invariant distribution \n",
    "\n",
    "**1) Irreduciblity**\n",
    "\n",
    "Definition A Markov chain with transition matrix $P$ is **irreducible** if: \n",
    "* $\\forall i, j \\in K$ $\\exists n$ such that $[P^n](i,j) > 0$\n",
    "* So for each $i$ and $j$, there exists a path of transitions leading from $i$ to $j$ (we can reach any state from any other state, possible after some number of steps)\n",
    "\n",
    "**2) Aperiodicity**\n",
    "\n",
    "Definition: A Markov chain with transition matrix $P$ is **aperiodic** if \n",
    "* $\\forall i, j \\in K$ $\\text{gcd} [n$ such that $[P^n](i,j) > 0] = 1$\n",
    "\n",
    "* A chain does not return to a given state periodically, so the greatest common divisor of the set of all possible return times to a state is $1$\n",
    "\n",
    "* If the gcd of these cycle lengths is greater than $1$, it means that the chain returns to the state in a periodic manner, with a specific period\n",
    "\n",
    "### **Fundamental Theorem of Markov Chains**\n",
    "\n",
    "If $P$ is irreducible and aperiodic, then it has a unique variant distribution $\\pi$ with $\\pi(i) > 0$ for all $i$. Also, the distribution after $n$ steps converges to $\\pi$ as $n \\rightarrow \\infty$ for any initial distribution $\\pi_0$\n",
    "\n",
    "So: \n",
    "* $\\forall P[X_n = i] \\rightarrow \\pi(i)$ as $n \\rightarrow \\infty$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
